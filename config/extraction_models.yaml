# Extraction Models Configuration
# This is the small/medium LLM that extracts atomic memories from conversations

current: ollama

ollama:
  enabled: true
  base_url: http://localhost:11434
  model: llama3.1:8b

openrouter:
  enabled: false
  api_key: YOUR_OPENROUTER_API_KEY_HERE
  base_url: https://openrouter.ai/api/v1
  model: meta-llama/llama-3.1-8b-instruct:free

openai:
  enabled: false
  api_key: YOUR_OPENAI_API_KEY_HERE
  base_url: https://api.openai.com/v1
  model: gpt-4o-mini
